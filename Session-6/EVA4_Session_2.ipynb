{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0m2JWFliFfKT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc= f'{epoch} - Training loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
      "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
      "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
      "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
      "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
      "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
      "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
      "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
      "================================================================\n",
      "Total params: 6,379,786\n",
      "Trainable params: 6,379,786\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.51\n",
      "Params size (MB): 24.34\n",
      "Estimated Total Size (MB): 25.85\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/qt1089d14r50f78yg8tx_prc0000gp/T/ipykernel_1093/1857902093.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1) #input -? OUtput? RF\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(256, 512, 3)\n",
    "        self.conv6 = nn.Conv2d(512, 1024, 3)\n",
    "        self.conv7 = nn.Conv2d(1024, 10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
    "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
    "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 8, 8])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "            Conv2d-2            [-1, 8, 28, 28]             584\n",
      "            Conv2d-3           [-1, 16, 28, 28]           1,168\n",
      "            Conv2d-4           [-1, 16, 28, 28]           2,320\n",
      "            Conv2d-5           [-1, 32, 26, 26]           4,640\n",
      "            Conv2d-6           [-1, 32, 24, 24]           9,248\n",
      "            Conv2d-7           [-1, 64, 22, 22]          18,496\n",
      "            Conv2d-8           [-1, 64, 20, 20]          36,928\n",
      "            Conv2d-9          [-1, 128, 18, 18]          73,856\n",
      "           Conv2d-10          [-1, 128, 16, 16]         147,584\n",
      "           Conv2d-11          [-1, 128, 14, 14]         147,584\n",
      "           Conv2d-12          [-1, 128, 12, 12]         147,584\n",
      "           Conv2d-13          [-1, 128, 10, 10]         147,584\n",
      "           Conv2d-14            [-1, 128, 8, 8]         147,584\n",
      "================================================================\n",
      "Total params: 885,240\n",
      "Trainable params: 885,240\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.08\n",
      "Params size (MB): 3.38\n",
      "Estimated Total Size (MB): 5.46\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nv/qt1089d14r50f78yg8tx_prc0000gp/T/ipykernel_1093/2877682149.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1) #input -? OUtput? RF\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3, padding=1)\n",
    "        # self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(16, 16, 3, padding=1)\n",
    "        # self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Conv2d(16, 32, 3, padding=0)\n",
    "        self.conv6 = nn.Conv2d(32, 32, 3, padding=0)\n",
    "        self.conv7 = nn.Conv2d(32, 64, 3, padding=0)\n",
    "        self.conv8 = nn.Conv2d(64, 64, 3, padding=0)\n",
    "        self.conv9 = nn.Conv2d(64, 128, 3, padding=0)\n",
    "        self.conv10 = nn.Conv2d(128, 128, 3, padding=0)\n",
    "        self.conv11 = nn.Conv2d(128, 128, 3, padding=0)\n",
    "        self.conv12 = nn.Conv2d(128, 128, 3, padding=0)\n",
    "        self.conv13 = nn.Conv2d(128, 128, 3, padding=0)\n",
    "        self.conv14 = nn.Conv2d(128, 128, 3, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.conv14(x)\n",
    "        # x = x.view(-1,10)\n",
    "        print(x.shape)\n",
    "        # x = nn.Linear(x, out_features=10, bias=True)\n",
    "\n",
    "        return F.log_softmax(x)\n",
    "        # x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
    "        # x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
    "        # x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
    "        # x = F.relu(self.conv7(x))\n",
    "        # x = x.view(-1, 10)\n",
    "\n",
    "model = Net1().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128, 7, 7])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "            Conv2d-2           [-1, 16, 28, 28]           1,168\n",
      "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
      "            Conv2d-4           [-1, 32, 14, 14]           4,640\n",
      "            Conv2d-5           [-1, 64, 14, 14]          18,496\n",
      "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
      "            Conv2d-7            [-1, 128, 7, 7]          73,856\n",
      "            Conv2d-8            [-1, 128, 7, 7]         147,584\n",
      "            Linear-9                  [-1, 256]       1,605,888\n",
      "           Linear-10                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 1,854,282\n",
      "Trainable params: 1,854,282\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.43\n",
      "Params size (MB): 7.07\n",
      "Estimated Total Size (MB): 7.51\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)  # Input: 28x28, Output: 28x28\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)  # Input: 28x28, Output: 28x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # Input: 28x28, Output: 14x14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)  # Input: 14x14, Output: 14x14\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=1)  # Input: 14x14, Output: 14x14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # Input: 14x14, Output: 7x7\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)  # Input: 7x7, Output: 7x7\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)  # Input: 7x7, Output: 7x7\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 256)  # Flatten from 128x7x7 to 256 neurons\n",
    "        self.fc2 = nn.Linear(256, 10)  # Output layer for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions with ReLU and pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        print(x.size())\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 128*7*7)\n",
    "        \n",
    "        # Fully connected layers with ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No activation here; handled by softmax below\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)  # Log softmax over class dimension\n",
    "    \n",
    "model = Net2().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MMWbLWO6FuHb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.1337766796350479 batch_id=468: 100%|██████████| 469/469 [01:18<00:00,  5.98it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0955, Accuracy: 9681/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.07053033262491226 batch_id=468: 100%|██████████| 469/469 [01:19<00:00,  5.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0598, Accuracy: 9800/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.03164953365921974 batch_id=468: 100%|██████████| 469/469 [01:17<00:00,  6.06it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0431, Accuracy: 9864/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.05276312306523323 batch_id=468: 100%|██████████| 469/469 [01:17<00:00,  6.05it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0472, Accuracy: 9854/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02243614010512829 batch_id=468: 100%|██████████| 469/469 [01:17<00:00,  6.03it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 9885/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04417748376727104 batch_id=468: 100%|██████████| 469/469 [01:17<00:00,  6.06it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 9884/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.020349102094769478 batch_id=468: 100%|██████████| 469/469 [01:16<00:00,  6.13it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0387, Accuracy: 9877/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.005820386577397585 batch_id=468: 100%|██████████| 469/469 [01:17<00:00,  6.06it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 9883/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.002598205115646124 batch_id=468: 100%|██████████| 469/469 [01:18<00:00,  6.01it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0366, Accuracy: 9901/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0027463010046631098 batch_id=468: 100%|██████████| 469/469 [01:19<00:00,  5.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0379, Accuracy: 9896/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net2().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "So5uk4EkHW6R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss=0.24829816818237305 batch_id=468: 100%|██████████| 469/469 [01:20<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1499, Accuracy: 9512/10000 (95%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss=0.061519164592027664 batch_id=468: 100%|██████████| 469/469 [01:21<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0871, Accuracy: 9711/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss=0.04699212685227394 batch_id=468: 100%|██████████| 469/469 [01:20<00:00,  5.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0612, Accuracy: 9809/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss=0.006802314426749945 batch_id=468: 100%|██████████| 469/469 [01:19<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0576, Accuracy: 9809/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss=0.0237752553075552 batch_id=468: 100%|██████████| 469/469 [01:21<00:00,  5.75it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0444, Accuracy: 9848/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network -3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "            Conv2d-2            [-1, 8, 28, 28]             584\n",
      "         MaxPool2d-3            [-1, 8, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 14, 14]           1,168\n",
      "            Conv2d-5           [-1, 16, 14, 14]           2,320\n",
      "         MaxPool2d-6             [-1, 16, 7, 7]               0\n",
      "            Conv2d-7             [-1, 32, 7, 7]           4,640\n",
      "            Conv2d-8             [-1, 32, 7, 7]           9,248\n",
      "            Linear-9                  [-1, 256]         401,664\n",
      "           Linear-10                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 422,274\n",
      "Trainable params: 422,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.19\n",
      "Params size (MB): 1.61\n",
      "Estimated Total Size (MB): 1.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)  # Input: 28x28, Output: 28x28\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3, padding=1)  # Input: 28x28, Output: 28x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # Input: 28x28, Output: 14x14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)  # Input: 14x14, Output: 14x14\n",
    "        self.conv4 = nn.Conv2d(16, 16, 3, padding=1)  # Input: 14x14, Output: 14x14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # Input: 14x14, Output: 7x7\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(16, 32, 3, padding=1)  # Input: 7x7, Output: 7x7\n",
    "        self.conv6 = nn.Conv2d(32, 32, 3, padding=1)  # Input: 7x7, Output: 7x7\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 256)  # Flatten from 128x7x7 to 256 neurons\n",
    "        self.fc2 = nn.Linear(256, 10)  # Output layer for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions with ReLU and pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        # print(x.size())\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 128*7*7)\n",
    "        \n",
    "        # Fully connected layers with ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No activation here; handled by softmax below\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)  # Log softmax over class dimension\n",
    "    \n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net3().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 - Training loss=0.23439884185791016 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2475, Accuracy: 9238/10000 (92%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 - Training loss=0.18272435665130615 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1359, Accuracy: 9556/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 - Training loss=0.3022434413433075 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1000, Accuracy: 9659/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4 - Training loss=0.024944975972175598 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0719, Accuracy: 9762/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 - Training loss=0.08905235677957535 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0627, Accuracy: 9798/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net3().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network -4 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "            Conv2d-2            [-1, 8, 28, 28]             584\n",
      "         MaxPool2d-3            [-1, 8, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 14, 14]           1,168\n",
      "            Conv2d-5           [-1, 16, 14, 14]           2,320\n",
      "         MaxPool2d-6             [-1, 16, 7, 7]               0\n",
      "            Conv2d-7             [-1, 32, 7, 7]           4,640\n",
      "            Conv2d-8             [-1, 32, 7, 7]           9,248\n",
      "            Linear-9                   [-1, 50]          78,450\n",
      "           Linear-10                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 97,000\n",
      "Trainable params: 97,000\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.19\n",
      "Params size (MB): 0.37\n",
      "Estimated Total Size (MB): 0.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net4, self).__init__()\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)  # Input: 28x28, Output: 28x28\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3, padding=1)  # Input: 28x28, Output: 28x28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # Input: 28x28, Output: 14x14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)  # Input: 14x14, Output: 14x14\n",
    "        self.conv4 = nn.Conv2d(16, 16, 3, padding=1)  # Input: 14x14, Output: 14x14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # Input: 14x14, Output: 7x7\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(16, 32, 3, padding=1)  # Input: 7x7, Output: 7x7\n",
    "        self.conv6 = nn.Conv2d(32, 32, 3, padding=1)  # Input: 7x7, Output: 7x7\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 50)  # Flatten from 128x7x7 to 256 neurons\n",
    "        self.fc2 = nn.Linear(50, 10)  # Output layer for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions with ReLU and pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        # print(x.size())\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 128*7*7)\n",
    "        \n",
    "        # Fully connected layers with ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No activation here; handled by softmax below\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)  # Log softmax over class dimension\n",
    "    \n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net4().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 - Training loss=0.48026803135871887 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3544, Accuracy: 8996/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 - Training loss=0.23670661449432373 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1950, Accuracy: 9411/10000 (94%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 - Training loss=0.22457338869571686 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1391, Accuracy: 9573/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4 - Training loss=0.1355208456516266 batch_id=468: 100%|██████████| 469/469 [00:41<00:00, 11.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1155, Accuracy: 9647/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 - Training loss=0.02095029503107071 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0937, Accuracy: 9695/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net4().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets increase the number of epochs and observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 - Training loss=0.31195130944252014 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3531, Accuracy: 8958/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 - Training loss=0.26081863045692444 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2284, Accuracy: 9274/10000 (93%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 - Training loss=0.1638379544019699 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1719, Accuracy: 9468/10000 (95%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4 - Training loss=0.1842859387397766 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.60it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1365, Accuracy: 9584/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 - Training loss=0.11313863843679428 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1198, Accuracy: 9622/10000 (96%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6 - Training loss=0.10510580986738205 batch_id=468: 100%|██████████| 469/469 [00:45<00:00, 10.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0969, Accuracy: 9693/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7 - Training loss=0.07871787995100021 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0825, Accuracy: 9729/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8 - Training loss=0.05509542301297188 batch_id=468: 100%|██████████| 469/469 [00:45<00:00, 10.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0823, Accuracy: 9739/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9 - Training loss=0.058538198471069336 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0682, Accuracy: 9772/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 - Training loss=0.04845879599452019 batch_id=468: 100%|██████████| 469/469 [00:41<00:00, 11.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0664, Accuracy: 9784/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11 - Training loss=0.06359484046697617 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0598, Accuracy: 9808/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 - Training loss=0.03301612660288811 batch_id=468: 100%|██████████| 469/469 [00:45<00:00, 10.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0545, Accuracy: 9813/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13 - Training loss=0.06893438845872879 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0572, Accuracy: 9808/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 - Training loss=0.0638401135802269 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.65it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0533, Accuracy: 9819/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15 - Training loss=0.030032888054847717 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0559, Accuracy: 9820/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 - Training loss=0.05116453766822815 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0522, Accuracy: 9837/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 - Training loss=0.014517239294946194 batch_id=468: 100%|██████████| 469/469 [00:46<00:00, 10.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0452, Accuracy: 9852/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 - Training loss=0.007336278911679983 batch_id=468: 100%|██████████| 469/469 [00:43<00:00, 10.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0553, Accuracy: 9825/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19 - Training loss=0.0316123440861702 batch_id=468: 100%|██████████| 469/469 [00:44<00:00, 10.62it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0477, Accuracy: 9857/10000 (99%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 - Training loss=0.01684548333287239 batch_id=468: 100%|██████████| 469/469 [00:47<00:00,  9.96it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0495, Accuracy: 9841/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net4().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Increase learning rate from `1e-4 to 1e-2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 - Training loss=0.1377662569284439 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 11.12it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0889, Accuracy: 9729/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 - Training loss=0.10433440655469894 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0710, Accuracy: 9779/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 - Training loss=0.0414019413292408 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0623, Accuracy: 9809/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4 - Training loss=0.06991016119718552 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0718, Accuracy: 9789/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 - Training loss=0.07675854116678238 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0593, Accuracy: 9821/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6 - Training loss=0.07673029601573944 batch_id=468: 100%|██████████| 469/469 [00:42<00:00, 10.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0675, Accuracy: 9782/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7 - Training loss=0.05237347260117531 batch_id=468: 100%|██████████| 469/469 [00:41<00:00, 11.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0552, Accuracy: 9840/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8 - Training loss=0.07142181694507599 batch_id=468: 100%|██████████| 469/469 [00:41<00:00, 11.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0761, Accuracy: 9800/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9 - Training loss=0.049256596714258194 batch_id=468: 100%|██████████| 469/469 [00:40<00:00, 11.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0641, Accuracy: 9812/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 - Training loss=0.10781421512365341 batch_id=468: 100%|██████████| 469/469 [00:41<00:00, 11.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0665, Accuracy: 9803/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Net4().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network - 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 320]' is invalid for input of size 8192",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cuda \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m Net5()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 26\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mNet5.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(F\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x), \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 320]' is invalid for input of size 8192"
     ]
    }
   ],
   "source": [
    "class Net5(nn.Module):\n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        super(Net5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3) # 26\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) # 24\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3) # 22\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3) # 20\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x), 2)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(self.conv3(x), 2)\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net5().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
